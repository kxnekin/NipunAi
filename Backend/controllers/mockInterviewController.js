const fetch = (...args) => import("node-fetch").then(({ default: fetch }) => fetch(...args));

// ğŸ¯ Gemini AI feedback generator â€” Final AI Studioâ€“ready version
exports.generateFeedback = async (req, res) => {
  try {
    const prompt = req.body?.prompt || "";
    console.log("ğŸ§  Incoming prompt:", prompt.slice(0, 100) + "...");

    if (!process.env.GEMINI_API_KEY) {
      return res.json({ text: "âš ï¸ GEMINI_API_KEY not set in .env file." });
    }

    const { GoogleGenerativeAI } = await import("@google/generative-ai");
    const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

    // âœ… AI Studio models only
    const models = ["gemini-1.5-pro-latest", "gemini-1.5-flash-latest"];
    let text = null;

    for (const name of models) {
      try {
        console.log(`ğŸ” Trying model: ${name}`);
        const model = genAI.getGenerativeModel({ model: name });
        const result = await model.generateContent([
          {
            role: "user",
            parts: [
              { text: prompt },
              { text: "\nEvaluate this interview answer with 3 improvement tips and a score /10." }
            ]
          }
        ]);
        text = result.response.text();
        console.log(`âœ… Success with ${name}`);
        break;
      } catch (err) {
        console.warn(`âš ï¸ ${name} failed ->`, err.message);
      }
    }

    if (!text) {
      console.log("âš ï¸ Fallback feedback used");
      text = `
**Interview Feedback (Fallback)**  
Your answer shows good clarity and interest in teamwork.  
âœ… Confident tone, positive attitude.  
ğŸ’¡ Add measurable examples (projects, results).  
â­ Estimated Score: 8/10`;
    }

    return res.json({ text });
  } catch (err) {
    console.error("âŒ Gemini error:", err.message);
    return res.json({
      text: "âš ï¸ Gemini API temporarily unavailable. Please try again later."
    });
  }
};

// ğŸ™ï¸ Audio transcription using OpenAI Whisper
exports.transcribeAudio = async (req, res) => {
  try {
    const audio = req.file;
    if (!audio) return res.status(400).json({ error: "No audio uploaded" });

    const formData = new FormData();
    const blob = new Blob([audio.buffer], { type: "audio/webm" });
    formData.append("file", blob, "recording.webm");
    formData.append("model", "whisper-1");

    const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
      method: "POST",
      headers: { Authorization: `Bearer ${process.env.OPENAI_API_KEY}` },
      body: formData,
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(errorText);
    }

    const data = await response.json();
    console.log("âœ… Transcription successful");
    res.json({ transcript: data.text });
  } catch (err) {
    console.error("âŒ Transcription error:", err.message);
    res.status(500).json({ error: "Failed to transcribe audio" });
  }
};

// ğŸš« Simple blocked notice
exports.blockedNotice = (req, res) => {
  res.json({ message: "ğŸš« This feature is temporarily blocked. Please try again later." });
};